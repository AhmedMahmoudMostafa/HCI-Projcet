{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrv_oPeazMW1"
   },
   "source": [
    "# **1. Setting up Dependencies**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fK89H5y-zxK2"
   },
   "source": [
    "## Connect to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\ahmme\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ahmme\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDoRXn7szzfs"
   },
   "source": [
    "## Download Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TN0LCgBdsFmp",
    "outputId": "3f174030-2d93-432e-8fa5-08b205ce1c13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov7'...\n",
      "Updating files:  75% (82/108)\n",
      "Updating files:  76% (83/108)\n",
      "Updating files:  77% (84/108)\n",
      "Updating files:  78% (85/108)\n",
      "Updating files:  79% (86/108)\n",
      "Updating files:  80% (87/108)\n",
      "Updating files:  81% (88/108)\n",
      "Updating files:  82% (89/108)\n",
      "Updating files:  83% (90/108)\n",
      "Updating files:  84% (91/108)\n",
      "Updating files:  85% (92/108)\n",
      "Updating files:  86% (93/108)\n",
      "Updating files:  87% (94/108)\n",
      "Updating files:  88% (96/108)\n",
      "Updating files:  89% (97/108)\n",
      "Updating files:  90% (98/108)\n",
      "Updating files:  91% (99/108)\n",
      "Updating files:  92% (100/108)\n",
      "Updating files:  93% (101/108)\n",
      "Updating files:  94% (102/108)\n",
      "Updating files:  95% (103/108)\n",
      "Updating files:  96% (104/108)\n",
      "Updating files:  97% (105/108)\n",
      "Updating files:  98% (106/108)\n",
      "Updating files:  99% (107/108)\n",
      "Updating files: 100% (108/108)\n",
      "Updating files: 100% (108/108), done.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/WongKinYiu/yolov7.git\n",
    "!cd yolov7\n",
    "!wget https://raw.githubusercontent.com/WongKinYiu/yolov7/u5/requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EduErUJar6ms",
    "outputId": "6e50c72d-7e94-4265-b455-ecd2f223e67d"
   },
   "outputs": [],
   "source": [
    "cd \"C:/Users/Ahmme/Downloads/Yolo-20231224T203553Z-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "P8DjahXwsgqa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/Ahmme/Downloads/Yolo-20231224T203553Z-001/Yolo/yolov7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eKkuPUA0zkrF",
    "outputId": "2e30d0d8-b11f-4df8-ca32-a525046b1f52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmme\\Downloads\\Yolo-20231224T203553Z-001\\Yolo\\yolov7\n"
     ]
    }
   ],
   "source": [
    "cd \"C:/Users/Ahmme/Downloads/Yolo-20231224T203553Z-001/Yolo/yolov7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JK14Uop0ztQq"
   },
   "source": [
    "## Getting Yolo Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ArX9q6N09jV"
   },
   "source": [
    "## Display Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "S3Ga2TlE1N8D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ahmme\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ahmme\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "import tensorflow as tf\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
    "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
    "\n",
    "\n",
    "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = img.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    ratio = r, r  # width, height ratios\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "    elif scaleFill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return img, ratio, (dw, dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2J93SWi09Vl"
   },
   "source": [
    "##Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "pNruLih21A8I"
   },
   "outputs": [],
   "source": [
    "classes_to_filter = None #You can give list of classes to filter by name ['train','person' ]\n",
    "\n",
    "\n",
    "opt  = {\n",
    "    \"weights\": \"weights/yolov7.pt\", # Path to weights file default weights are for nano model\n",
    "    \"yaml\"   : \"data/coco.yaml\",\n",
    "    \"img-size\": 640, # default image size\n",
    "    \"conf-thres\": 0.25, # confidence threshold for inference.\n",
    "    \"iou-thres\" : 0.45, # NMS IoU threshold for inference.\n",
    "    \"device\" : 'cpu',  # device to run our model i.e. 0 or 0,1,2,3 or cpu\n",
    "    \"classes\" : classes_to_filter  # list of classes to filter or None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDDWC3oR1w8J"
   },
   "source": [
    "#**2. Running on a single image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEUyUCJg2MHQ",
    "outputId": "df3b52a0-a5ec-47c3-cc5f-302690a71f13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  v0.1-128-ga207844 torch 2.1.0+cu118 CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "640x640 2 bananas, \n",
      "640x640 2 bananas, 5 apples, \n",
      "640x640 2 bananas, 5 apples, 2 oranges, \n"
     ]
    }
   ],
   "source": [
    "# Give path of source image\n",
    "source_image_path = \"C:/Users/Ahmme/Downloads/https___data.amirite.com_posts_a6_b7_a6369648176e.jpg\"\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  weights, imgsz = opt['weights'], opt['img-size']\n",
    "  set_logging()\n",
    "  device = select_device(opt['device'])\n",
    "  half = device.type != 'cpu'\n",
    "  model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "  stride = int(model.stride.max())  # model stride\n",
    "  imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
    "  if half:\n",
    "    model.half()\n",
    "\n",
    "  names = model.module.names if hasattr(model, 'module') else model.names\n",
    "  colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "  if device.type != 'cpu':\n",
    "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "\n",
    "  img0 = cv2.imread(source_image_path)\n",
    "  img = letterbox(img0, imgsz, stride=stride)[0]\n",
    "  img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "  img = np.ascontiguousarray(img)\n",
    "  img = torch.from_numpy(img).to(device)\n",
    "  img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "  img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "  if img.ndimension() == 3:\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "  # Inference\n",
    "  t1 = time_synchronized()\n",
    "  pred = model(img, augment= False)[0]\n",
    "\n",
    "  # Apply NMS\n",
    "  classes = None\n",
    "  if opt['classes']:\n",
    "    classes = []\n",
    "    for class_name in opt['classes']:\n",
    "\n",
    "      classes.append(names.index(class_name))\n",
    "\n",
    "  if classes:\n",
    "\n",
    "    classes = [i for i in range(len(names)) if i not in classes]\n",
    "\n",
    "\n",
    "  pred = non_max_suppression(pred, opt['conf-thres'], opt['iou-thres'], classes= classes, agnostic= False)\n",
    "  t2 = time_synchronized()\n",
    "  for i, det in enumerate(pred):\n",
    "    s = ''\n",
    "    s += '%gx%g ' % img.shape[2:]  # print string\n",
    "    gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]\n",
    "    if len(det):\n",
    "      det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "\n",
    "      for c in det[:, -1].unique():\n",
    "        n = (det[:, -1] == c).sum()  # detections per class\n",
    "        s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "        print(s)\n",
    "\n",
    "      for *xyxy, conf, cls in reversed(det):\n",
    "\n",
    "        label = f'{names[int(cls)]} {conf:.2f}'\n",
    "        plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lOX4M6nw2wXa",
    "outputId": "6e2e1535-f156-478b-9711-ebcfb2aae201"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imshow('Image', img0)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuArtpXr1-hQ"
   },
   "source": [
    "#**3.Running YOLOv7 on Video**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "US8TNSKd9Nn4"
   },
   "source": [
    "# using video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ki0E08xM9NcD"
   },
   "source": [
    "##Enter Video Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "m5r7bjuG9FIk"
   },
   "outputs": [],
   "source": [
    "#give the full path to video, your video will be in the Yolov7 folder\n",
    "video_path = \"C:/Users/Ahmme/Downloads/pexels_videos_2016738 (1080p).mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVFVOPgE-BzG"
   },
   "source": [
    "##Run Yolo on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCkPm1g7-EAJ",
    "outputId": "956178f1-c30d-44d5-e3f9-6f4be4ac42b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  v0.1-128-ga207844 torch 2.1.0+cu118 CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "384x640 1 apple, \n",
      "384x640 1 apple, 22 oranges, \n",
      "1/228 frames processed\n",
      "384x640 1 apple, \n",
      "384x640 1 apple, 21 oranges, \n",
      "2/228 frames processed\n",
      "384x640 2 apples, \n",
      "384x640 2 apples, 19 oranges, \n",
      "3/228 frames processed\n",
      "384x640 3 apples, \n",
      "384x640 3 apples, 20 oranges, \n",
      "4/228 frames processed\n",
      "384x640 2 apples, \n",
      "384x640 2 apples, 18 oranges, \n",
      "5/228 frames processed\n",
      "384x640 3 apples, \n",
      "384x640 3 apples, 17 oranges, \n",
      "6/228 frames processed\n",
      "384x640 2 apples, \n",
      "384x640 2 apples, 20 oranges, \n",
      "7/228 frames processed\n",
      "384x640 2 apples, \n",
      "384x640 2 apples, 17 oranges, \n",
      "8/228 frames processed\n",
      "384x640 2 apples, \n",
      "384x640 2 apples, 19 oranges, \n",
      "9/228 frames processed\n",
      "384x640 2 apples, \n",
      "384x640 2 apples, 17 oranges, \n",
      "10/228 frames processed\n",
      "384x640 2 apples, \n",
      "384x640 2 apples, 19 oranges, \n",
      "11/228 frames processed\n",
      "384x640 1 person, \n",
      "384x640 1 person, 4 apples, \n",
      "384x640 1 person, 4 apples, 18 oranges, \n",
      "12/228 frames processed\n",
      "384x640 1 person, \n",
      "384x640 1 person, 3 apples, \n",
      "384x640 1 person, 3 apples, 16 oranges, \n",
      "13/228 frames processed\n",
      "384x640 1 person, \n",
      "384x640 1 person, 3 apples, \n",
      "384x640 1 person, 3 apples, 18 oranges, \n",
      "14/228 frames processed\n",
      "384x640 1 person, \n",
      "384x640 1 person, 3 apples, \n",
      "384x640 1 person, 3 apples, 18 oranges, \n",
      "15/228 frames processed\n",
      "384x640 1 person, \n",
      "384x640 1 person, 3 apples, \n",
      "384x640 1 person, 3 apples, 17 oranges, \n",
      "16/228 frames processed\n",
      "384x640 1 person, \n",
      "384x640 1 person, 3 apples, \n",
      "384x640 1 person, 3 apples, 17 oranges, \n",
      "17/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 5 apples, \n",
      "384x640 2 persons, 5 apples, 16 oranges, \n",
      "18/228 frames processed\n",
      "384x640 1 person, \n",
      "384x640 1 person, 1 bowl, \n",
      "384x640 1 person, 1 bowl, 4 apples, \n",
      "384x640 1 person, 1 bowl, 4 apples, 20 oranges, \n",
      "19/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 3 apples, \n",
      "384x640 2 persons, 1 bowl, 3 apples, 15 oranges, \n",
      "20/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 3 apples, \n",
      "384x640 2 persons, 1 bowl, 3 apples, 20 oranges, \n",
      "21/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 4 apples, \n",
      "384x640 2 persons, 1 bowl, 4 apples, 20 oranges, \n",
      "22/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 5 apples, \n",
      "384x640 2 persons, 1 bowl, 5 apples, 19 oranges, \n",
      "23/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 6 apples, \n",
      "384x640 2 persons, 1 bowl, 6 apples, 23 oranges, \n",
      "24/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 6 apples, \n",
      "384x640 2 persons, 1 bowl, 6 apples, 23 oranges, \n",
      "25/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 4 apples, \n",
      "384x640 2 persons, 1 bowl, 4 apples, 20 oranges, \n",
      "26/228 frames processed\n",
      "384x640 1 person, \n",
      "384x640 1 person, 1 bowl, \n",
      "384x640 1 person, 1 bowl, 3 apples, \n",
      "384x640 1 person, 1 bowl, 3 apples, 19 oranges, \n",
      "27/228 frames processed\n",
      "384x640 1 person, \n",
      "384x640 1 person, 1 bowl, \n",
      "384x640 1 person, 1 bowl, 4 apples, \n",
      "384x640 1 person, 1 bowl, 4 apples, 23 oranges, \n",
      "28/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 3 apples, \n",
      "384x640 2 persons, 1 bowl, 3 apples, 21 oranges, \n",
      "29/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 4 apples, \n",
      "384x640 2 persons, 1 bowl, 4 apples, 20 oranges, \n",
      "30/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 5 apples, \n",
      "384x640 2 persons, 1 bowl, 5 apples, 22 oranges, \n",
      "31/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 5 apples, \n",
      "384x640 2 persons, 1 bowl, 5 apples, 20 oranges, \n",
      "32/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 6 apples, \n",
      "384x640 2 persons, 1 bowl, 6 apples, 19 oranges, \n",
      "33/228 frames processed\n",
      "384x640 3 persons, \n",
      "384x640 3 persons, 1 bowl, \n",
      "384x640 3 persons, 1 bowl, 6 apples, \n",
      "384x640 3 persons, 1 bowl, 6 apples, 21 oranges, \n",
      "34/228 frames processed\n",
      "384x640 3 persons, \n",
      "384x640 3 persons, 1 bowl, \n",
      "384x640 3 persons, 1 bowl, 5 apples, \n",
      "384x640 3 persons, 1 bowl, 5 apples, 23 oranges, \n",
      "384x640 3 persons, 1 bowl, 5 apples, 23 oranges, 1 cell phone, \n",
      "35/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 4 apples, \n",
      "384x640 2 persons, 1 bowl, 4 apples, 25 oranges, \n",
      "36/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 6 apples, \n",
      "384x640 2 persons, 1 bowl, 6 apples, 24 oranges, \n",
      "37/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 6 apples, \n",
      "384x640 2 persons, 1 bowl, 6 apples, 25 oranges, \n",
      "38/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 5 apples, \n",
      "384x640 2 persons, 1 bowl, 5 apples, 22 oranges, \n",
      "39/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 1 bowl, \n",
      "384x640 2 persons, 1 bowl, 8 apples, \n",
      "384x640 2 persons, 1 bowl, 8 apples, 21 oranges, \n",
      "40/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 5 apples, \n",
      "384x640 2 persons, 5 apples, 19 oranges, \n",
      "41/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 7 apples, \n",
      "384x640 2 persons, 7 apples, 22 oranges, \n",
      "42/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 7 apples, \n",
      "384x640 2 persons, 7 apples, 23 oranges, \n",
      "43/228 frames processed\n",
      "384x640 2 persons, \n",
      "384x640 2 persons, 6 apples, \n",
      "384x640 2 persons, 6 apples, 22 oranges, \n",
      "44/228 frames processed\n",
      "384x640 3 persons, \n",
      "384x640 3 persons, 6 apples, \n",
      "384x640 3 persons, 6 apples, 24 oranges, \n",
      "45/228 frames processed\n",
      "384x640 3 persons, \n",
      "384x640 3 persons, 7 apples, \n",
      "384x640 3 persons, 7 apples, 18 oranges, \n",
      "46/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 13 apples, \n",
      "384x640 4 persons, 13 apples, 22 oranges, \n",
      "47/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 8 apples, \n",
      "384x640 4 persons, 8 apples, 20 oranges, \n",
      "48/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 10 apples, \n",
      "384x640 4 persons, 10 apples, 16 oranges, \n",
      "49/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 8 apples, \n",
      "384x640 4 persons, 8 apples, 16 oranges, \n",
      "50/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 16 apples, \n",
      "384x640 4 persons, 1 bowl, 16 apples, 17 oranges, \n",
      "51/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 10 apples, \n",
      "384x640 4 persons, 1 bowl, 10 apples, 20 oranges, \n",
      "52/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 7 apples, \n",
      "384x640 4 persons, 7 apples, 15 oranges, \n",
      "53/228 frames processed\n",
      "384x640 3 persons, \n",
      "384x640 3 persons, 1 bowl, \n",
      "384x640 3 persons, 1 bowl, 7 apples, \n",
      "384x640 3 persons, 1 bowl, 7 apples, 12 oranges, \n",
      "54/228 frames processed\n",
      "384x640 3 persons, \n",
      "384x640 3 persons, 7 apples, \n",
      "384x640 3 persons, 7 apples, 13 oranges, \n",
      "55/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 17 oranges, \n",
      "56/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 10 apples, \n",
      "384x640 4 persons, 10 apples, 14 oranges, \n",
      "57/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 10 apples, \n",
      "384x640 4 persons, 1 bowl, 10 apples, 13 oranges, \n",
      "58/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 7 apples, \n",
      "384x640 4 persons, 7 apples, 14 oranges, \n",
      "59/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 11 oranges, \n",
      "60/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 9 apples, \n",
      "384x640 5 persons, 9 apples, 9 oranges, \n",
      "61/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 bowl, \n",
      "384x640 5 persons, 1 bowl, 13 apples, \n",
      "384x640 5 persons, 1 bowl, 13 apples, 11 oranges, \n",
      "62/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 8 apples, \n",
      "384x640 4 persons, 8 apples, 10 oranges, \n",
      "63/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 8 oranges, \n",
      "64/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 8 apples, \n",
      "384x640 4 persons, 8 apples, 7 oranges, \n",
      "65/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 8 apples, \n",
      "384x640 4 persons, 8 apples, 8 oranges, \n",
      "66/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 8 oranges, \n",
      "67/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 8 apples, \n",
      "384x640 4 persons, 8 apples, 10 oranges, \n",
      "68/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 11 apples, \n",
      "384x640 4 persons, 11 apples, 10 oranges, \n",
      "69/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 9 oranges, \n",
      "70/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 7 oranges, \n",
      "71/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 8 oranges, \n",
      "72/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 9 oranges, \n",
      "73/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 8 apples, \n",
      "384x640 4 persons, 1 bowl, 8 apples, 9 oranges, \n",
      "74/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, 8 oranges, \n",
      "75/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 handbag, \n",
      "384x640 5 persons, 1 handbag, 1 bowl, \n",
      "384x640 5 persons, 1 handbag, 1 bowl, 9 apples, \n",
      "384x640 5 persons, 1 handbag, 1 bowl, 9 apples, 8 oranges, \n",
      "76/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 handbag, \n",
      "384x640 5 persons, 1 handbag, 1 bowl, \n",
      "384x640 5 persons, 1 handbag, 1 bowl, 9 apples, \n",
      "384x640 5 persons, 1 handbag, 1 bowl, 9 apples, 9 oranges, \n",
      "77/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 10 apples, \n",
      "384x640 5 persons, 10 apples, 9 oranges, \n",
      "78/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 8 apples, \n",
      "384x640 4 persons, 1 bowl, 8 apples, 9 oranges, \n",
      "79/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 11 apples, \n",
      "384x640 4 persons, 1 bowl, 11 apples, 8 oranges, \n",
      "80/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 11 apples, \n",
      "384x640 4 persons, 1 bowl, 11 apples, 8 oranges, \n",
      "81/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 10 apples, \n",
      "384x640 4 persons, 1 bowl, 10 apples, 8 oranges, \n",
      "82/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 8 apples, \n",
      "384x640 4 persons, 1 bowl, 8 apples, 9 oranges, \n",
      "83/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 9 apples, \n",
      "384x640 4 persons, 1 bowl, 9 apples, 7 oranges, \n",
      "84/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 9 oranges, \n",
      "85/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 9 apples, \n",
      "384x640 4 persons, 1 bowl, 9 apples, 6 oranges, \n",
      "86/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 10 apples, \n",
      "384x640 4 persons, 10 apples, 4 oranges, \n",
      "87/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 4 oranges, \n",
      "88/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 8 apples, \n",
      "384x640 5 persons, 8 apples, 4 oranges, \n",
      "89/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 8 apples, \n",
      "384x640 4 persons, 8 apples, 5 oranges, \n",
      "90/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 8 apples, \n",
      "384x640 4 persons, 8 apples, 6 oranges, \n",
      "91/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 9 apples, \n",
      "384x640 5 persons, 9 apples, 3 oranges, \n",
      "92/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 9 apples, \n",
      "384x640 5 persons, 9 apples, 3 oranges, \n",
      "93/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 4 oranges, \n",
      "94/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 9 apples, \n",
      "384x640 4 persons, 1 handbag, 9 apples, 2 oranges, \n",
      "95/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 backpack, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, 9 apples, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, 9 apples, 3 oranges, \n",
      "96/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 9 apples, \n",
      "384x640 4 persons, 1 bowl, 9 apples, 2 oranges, \n",
      "97/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 backpack, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, 8 apples, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, 8 apples, 2 oranges, \n",
      "98/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 9 apples, \n",
      "384x640 4 persons, 1 handbag, 9 apples, 3 oranges, \n",
      "99/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 2 oranges, \n",
      "100/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 10 apples, \n",
      "384x640 4 persons, 10 apples, 2 oranges, \n",
      "101/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 7 apples, \n",
      "384x640 4 persons, 7 apples, 2 oranges, \n",
      "102/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 8 apples, \n",
      "384x640 4 persons, 1 handbag, 8 apples, 1 orange, \n",
      "103/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 1 orange, \n",
      "104/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 10 apples, \n",
      "384x640 5 persons, 10 apples, 1 orange, \n",
      "105/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 9 apples, \n",
      "384x640 5 persons, 9 apples, 2 oranges, \n",
      "106/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 9 apples, \n",
      "384x640 5 persons, 9 apples, 1 orange, \n",
      "107/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 8 apples, \n",
      "384x640 4 persons, 8 apples, 4 oranges, \n",
      "108/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 8 apples, \n",
      "384x640 5 persons, 8 apples, 2 oranges, \n",
      "109/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 10 apples, \n",
      "384x640 4 persons, 1 bowl, 10 apples, 2 oranges, \n",
      "110/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 backpack, \n",
      "384x640 5 persons, 1 backpack, 1 handbag, \n",
      "384x640 5 persons, 1 backpack, 1 handbag, 9 apples, \n",
      "384x640 5 persons, 1 backpack, 1 handbag, 9 apples, 1 orange, \n",
      "111/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 1 backpack, \n",
      "384x640 6 persons, 1 backpack, 1 handbag, \n",
      "384x640 6 persons, 1 backpack, 1 handbag, 7 apples, \n",
      "384x640 6 persons, 1 backpack, 1 handbag, 7 apples, 2 oranges, \n",
      "112/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 9 apples, \n",
      "384x640 5 persons, 9 apples, 2 oranges, \n",
      "113/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 8 apples, \n",
      "384x640 6 persons, 8 apples, 2 oranges, \n",
      "114/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 8 apples, \n",
      "384x640 6 persons, 8 apples, 2 oranges, \n",
      "115/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 8 apples, \n",
      "384x640 6 persons, 8 apples, 2 oranges, \n",
      "116/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 11 apples, \n",
      "384x640 6 persons, 11 apples, 1 orange, \n",
      "117/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 9 apples, \n",
      "384x640 6 persons, 9 apples, 1 orange, \n",
      "118/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 8 apples, \n",
      "384x640 6 persons, 8 apples, 3 oranges, \n",
      "119/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 11 apples, \n",
      "384x640 6 persons, 11 apples, 1 orange, \n",
      "120/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 10 apples, \n",
      "384x640 6 persons, 10 apples, 2 oranges, \n",
      "121/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 9 apples, \n",
      "122/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 9 apples, \n",
      "123/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 tie, \n",
      "384x640 5 persons, 1 tie, 9 apples, \n",
      "384x640 5 persons, 1 tie, 9 apples, 1 orange, \n",
      "124/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 tie, \n",
      "384x640 5 persons, 1 tie, 7 apples, \n",
      "384x640 5 persons, 1 tie, 7 apples, 1 orange, \n",
      "125/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 8 apples, \n",
      "384x640 4 persons, 1 handbag, 8 apples, 3 oranges, \n",
      "126/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 9 apples, \n",
      "384x640 4 persons, 1 handbag, 9 apples, 3 oranges, \n",
      "127/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 3 oranges, \n",
      "128/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 9 apples, \n",
      "384x640 4 persons, 9 apples, 2 oranges, \n",
      "129/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 9 apples, \n",
      "130/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 8 apples, \n",
      "131/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 8 apples, \n",
      "384x640 5 persons, 8 apples, 2 oranges, \n",
      "132/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 7 apples, \n",
      "384x640 5 persons, 7 apples, 1 orange, \n",
      "384x640 5 persons, 7 apples, 1 orange, 1 clock, \n",
      "133/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 7 apples, \n",
      "384x640 5 persons, 7 apples, 1 orange, \n",
      "134/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 7 apples, \n",
      "384x640 4 persons, 7 apples, 1 orange, \n",
      "135/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 7 apples, \n",
      "384x640 4 persons, 1 handbag, 7 apples, 1 orange, \n",
      "136/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 8 apples, \n",
      "384x640 4 persons, 8 apples, 1 orange, \n",
      "137/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 9 apples, \n",
      "384x640 4 persons, 1 handbag, 9 apples, 1 orange, \n",
      "138/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 7 apples, \n",
      "384x640 4 persons, 1 handbag, 7 apples, 1 orange, \n",
      "139/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 7 apples, \n",
      "384x640 4 persons, 1 handbag, 7 apples, 1 orange, \n",
      "140/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 8 apples, \n",
      "384x640 4 persons, 1 handbag, 8 apples, 1 orange, \n",
      "141/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 8 apples, \n",
      "384x640 4 persons, 1 handbag, 8 apples, 1 orange, \n",
      "142/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 8 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 8 apples, 1 orange, \n",
      "143/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 7 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 7 apples, 1 orange, \n",
      "144/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 8 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 8 apples, 1 orange, \n",
      "145/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 9 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 9 apples, 2 oranges, \n",
      "146/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, 2 oranges, \n",
      "147/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, 1 orange, \n",
      "148/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, \n",
      "149/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, \n",
      "150/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, \n",
      "151/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 8 apples, \n",
      "152/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 7 apples, \n",
      "153/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 9 apples, \n",
      "154/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 9 apples, \n",
      "155/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, \n",
      "156/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, \n",
      "157/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, 1 orange, \n",
      "158/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 8 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 8 apples, 1 orange, \n",
      "159/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 8 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 8 apples, 1 orange, \n",
      "160/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 tie, \n",
      "384x640 4 persons, 1 handbag, 1 tie, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 tie, 1 bowl, 10 apples, \n",
      "384x640 4 persons, 1 handbag, 1 tie, 1 bowl, 10 apples, 1 orange, \n",
      "161/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 tie, \n",
      "384x640 4 persons, 1 handbag, 1 tie, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 tie, 1 bowl, 9 apples, \n",
      "162/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 9 apples, \n",
      "163/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 9 apples, \n",
      "164/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, 1 orange, \n",
      "165/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 11 apples, \n",
      "384x640 4 persons, 1 bowl, 11 apples, 1 orange, \n",
      "166/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 13 apples, \n",
      "167/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bottle, \n",
      "384x640 4 persons, 1 bottle, 1 bowl, \n",
      "384x640 4 persons, 1 bottle, 1 bowl, 11 apples, \n",
      "384x640 4 persons, 1 bottle, 1 bowl, 11 apples, 1 cell phone, \n",
      "168/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bottle, \n",
      "384x640 4 persons, 1 bottle, 1 bowl, \n",
      "384x640 4 persons, 1 bottle, 1 bowl, 9 apples, \n",
      "384x640 4 persons, 1 bottle, 1 bowl, 9 apples, 1 cell phone, \n",
      "169/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 9 apples, \n",
      "384x640 4 persons, 1 bowl, 9 apples, 1 cell phone, \n",
      "170/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 9 apples, \n",
      "384x640 4 persons, 1 bowl, 9 apples, 1 cell phone, \n",
      "171/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 9 apples, \n",
      "384x640 4 persons, 1 bowl, 9 apples, 1 cell phone, \n",
      "172/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 cup, \n",
      "384x640 4 persons, 1 cup, 1 bowl, \n",
      "384x640 4 persons, 1 cup, 1 bowl, 11 apples, \n",
      "384x640 4 persons, 1 cup, 1 bowl, 11 apples, 1 orange, \n",
      "384x640 4 persons, 1 cup, 1 bowl, 11 apples, 1 orange, 1 cell phone, \n",
      "173/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 10 apples, \n",
      "384x640 4 persons, 1 bowl, 10 apples, 1 carrot, \n",
      "384x640 4 persons, 1 bowl, 10 apples, 1 carrot, 1 cell phone, \n",
      "174/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 bowl, \n",
      "384x640 4 persons, 1 bowl, 9 apples, \n",
      "384x640 4 persons, 1 bowl, 9 apples, 1 carrot, \n",
      "384x640 4 persons, 1 bowl, 9 apples, 1 carrot, 1 cell phone, \n",
      "175/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, \n",
      "176/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, 1 carrot, \n",
      "177/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, 1 orange, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, 1 orange, 2 carrots, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 10 apples, 1 orange, 2 carrots, 1 clock, \n",
      "178/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, 1 orange, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, 1 orange, 1 broccoli, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, 1 orange, 1 broccoli, 1 carrot, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, 1 orange, 1 broccoli, 1 carrot, 1 cell phone, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 11 apples, 1 orange, 1 broccoli, 1 carrot, 1 cell phone, 1 clock, \n",
      "179/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 12 apples, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 12 apples, 1 broccoli, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 12 apples, 1 broccoli, 1 carrot, \n",
      "384x640 4 persons, 1 handbag, 1 bowl, 12 apples, 1 broccoli, 1 carrot, 1 clock, \n",
      "180/228 frames processed\n",
      "384x640 3 persons, \n",
      "384x640 3 persons, 2 handbags, \n",
      "384x640 3 persons, 2 handbags, 1 bowl, \n",
      "384x640 3 persons, 2 handbags, 1 bowl, 12 apples, \n",
      "384x640 3 persons, 2 handbags, 1 bowl, 12 apples, 1 broccoli, \n",
      "384x640 3 persons, 2 handbags, 1 bowl, 12 apples, 1 broccoli, 1 carrot, \n",
      "384x640 3 persons, 2 handbags, 1 bowl, 12 apples, 1 broccoli, 1 carrot, 1 clock, \n",
      "181/228 frames processed\n",
      "384x640 3 persons, \n",
      "384x640 3 persons, 3 handbags, \n",
      "384x640 3 persons, 3 handbags, 1 bowl, \n",
      "384x640 3 persons, 3 handbags, 1 bowl, 14 apples, \n",
      "384x640 3 persons, 3 handbags, 1 bowl, 14 apples, 1 broccoli, \n",
      "384x640 3 persons, 3 handbags, 1 bowl, 14 apples, 1 broccoli, 1 carrot, \n",
      "384x640 3 persons, 3 handbags, 1 bowl, 14 apples, 1 broccoli, 1 carrot, 1 cell phone, \n",
      "384x640 3 persons, 3 handbags, 1 bowl, 14 apples, 1 broccoli, 1 carrot, 1 cell phone, 1 clock, \n",
      "182/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 3 handbags, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 14 apples, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 14 apples, 1 broccoli, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 14 apples, 1 broccoli, 1 cell phone, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 14 apples, 1 broccoli, 1 cell phone, 1 clock, \n",
      "183/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 13 apples, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 13 apples, 1 broccoli, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 13 apples, 1 broccoli, 1 book, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 13 apples, 1 broccoli, 1 book, 1 clock, \n",
      "184/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 12 apples, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 12 apples, 1 broccoli, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 12 apples, 1 broccoli, 1 carrot, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 12 apples, 1 broccoli, 1 carrot, 1 cell phone, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 12 apples, 1 broccoli, 1 carrot, 1 cell phone, 1 clock, \n",
      "185/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 3 handbags, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 11 apples, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 11 apples, 1 broccoli, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 11 apples, 1 broccoli, 1 carrot, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 11 apples, 1 broccoli, 1 carrot, 1 cell phone, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 11 apples, 1 broccoli, 1 carrot, 1 cell phone, 1 book, \n",
      "186/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 3 handbags, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 11 apples, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 11 apples, 1 broccoli, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 11 apples, 1 broccoli, 1 cell phone, \n",
      "384x640 4 persons, 3 handbags, 1 bowl, 11 apples, 1 broccoli, 1 cell phone, 1 book, \n",
      "187/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 2 handbags, \n",
      "384x640 5 persons, 2 handbags, 1 bowl, \n",
      "384x640 5 persons, 2 handbags, 1 bowl, 11 apples, \n",
      "384x640 5 persons, 2 handbags, 1 bowl, 11 apples, 1 broccoli, \n",
      "384x640 5 persons, 2 handbags, 1 bowl, 11 apples, 1 broccoli, 1 book, \n",
      "384x640 5 persons, 2 handbags, 1 bowl, 11 apples, 1 broccoli, 1 book, 1 clock, \n",
      "188/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 10 apples, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 10 apples, 1 broccoli, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 10 apples, 1 broccoli, 1 cell phone, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 10 apples, 1 broccoli, 1 cell phone, 1 book, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 10 apples, 1 broccoli, 1 cell phone, 1 book, 1 clock, \n",
      "189/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 1 tie, \n",
      "384x640 4 persons, 1 handbag, 1 tie, 1 bowl, \n",
      "384x640 4 persons, 1 handbag, 1 tie, 1 bowl, 11 apples, \n",
      "384x640 4 persons, 1 handbag, 1 tie, 1 bowl, 11 apples, 1 broccoli, \n",
      "384x640 4 persons, 1 handbag, 1 tie, 1 bowl, 11 apples, 1 broccoli, 1 carrot, \n",
      "384x640 4 persons, 1 handbag, 1 tie, 1 bowl, 11 apples, 1 broccoli, 1 carrot, 1 cell phone, \n",
      "190/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 1 tie, \n",
      "384x640 4 persons, 2 handbags, 1 tie, 1 bowl, \n",
      "384x640 4 persons, 2 handbags, 1 tie, 1 bowl, 12 apples, \n",
      "384x640 4 persons, 2 handbags, 1 tie, 1 bowl, 12 apples, 1 broccoli, \n",
      "384x640 4 persons, 2 handbags, 1 tie, 1 bowl, 12 apples, 1 broccoli, 1 cell phone, \n",
      "384x640 4 persons, 2 handbags, 1 tie, 1 bowl, 12 apples, 1 broccoli, 1 cell phone, 1 book, \n",
      "191/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 1 tie, \n",
      "384x640 4 persons, 2 handbags, 1 tie, 11 apples, \n",
      "384x640 4 persons, 2 handbags, 1 tie, 11 apples, 1 broccoli, \n",
      "384x640 4 persons, 2 handbags, 1 tie, 11 apples, 1 broccoli, 1 cell phone, \n",
      "384x640 4 persons, 2 handbags, 1 tie, 11 apples, 1 broccoli, 1 cell phone, 1 book, \n",
      "192/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 2 handbags, \n",
      "384x640 5 persons, 2 handbags, 1 tie, \n",
      "384x640 5 persons, 2 handbags, 1 tie, 11 apples, \n",
      "384x640 5 persons, 2 handbags, 1 tie, 11 apples, 1 broccoli, \n",
      "384x640 5 persons, 2 handbags, 1 tie, 11 apples, 1 broccoli, 1 cell phone, \n",
      "384x640 5 persons, 2 handbags, 1 tie, 11 apples, 1 broccoli, 1 cell phone, 1 book, \n",
      "193/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 11 apples, \n",
      "384x640 4 persons, 1 handbag, 11 apples, 1 cell phone, \n",
      "384x640 4 persons, 1 handbag, 11 apples, 1 cell phone, 1 book, \n",
      "194/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 backpack, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, 1 tie, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, 1 tie, 11 apples, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, 1 tie, 11 apples, 1 cell phone, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, 1 tie, 11 apples, 1 cell phone, 1 book, \n",
      "195/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 backpack, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, 11 apples, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, 11 apples, 1 cell phone, \n",
      "384x640 4 persons, 1 backpack, 1 handbag, 11 apples, 1 cell phone, 1 book, \n",
      "196/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 12 apples, \n",
      "384x640 4 persons, 1 handbag, 12 apples, 1 book, \n",
      "197/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 14 apples, \n",
      "384x640 4 persons, 2 handbags, 14 apples, 1 book, \n",
      "198/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 umbrella, \n",
      "384x640 4 persons, 1 umbrella, 2 handbags, \n",
      "384x640 4 persons, 1 umbrella, 2 handbags, 12 apples, \n",
      "384x640 4 persons, 1 umbrella, 2 handbags, 12 apples, 1 cell phone, \n",
      "199/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 11 apples, \n",
      "384x640 4 persons, 1 handbag, 11 apples, 1 cell phone, \n",
      "384x640 4 persons, 1 handbag, 11 apples, 1 cell phone, 1 clock, \n",
      "200/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 12 apples, \n",
      "201/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 13 apples, \n",
      "202/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 12 apples, \n",
      "384x640 4 persons, 1 handbag, 12 apples, 1 book, \n",
      "203/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 11 apples, \n",
      "384x640 4 persons, 11 apples, 1 book, \n",
      "204/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 12 apples, \n",
      "384x640 4 persons, 12 apples, 1 book, \n",
      "205/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 1 handbag, \n",
      "384x640 4 persons, 1 handbag, 9 apples, \n",
      "206/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 9 apples, \n",
      "207/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 9 apples, \n",
      "208/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 9 apples, \n",
      "209/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 8 apples, \n",
      "384x640 4 persons, 2 handbags, 8 apples, 1 book, \n",
      "384x640 4 persons, 2 handbags, 8 apples, 1 book, 1 clock, \n",
      "210/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 9 apples, \n",
      "384x640 4 persons, 2 handbags, 9 apples, 1 book, \n",
      "384x640 4 persons, 2 handbags, 9 apples, 1 book, 1 clock, \n",
      "211/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 8 apples, \n",
      "384x640 4 persons, 2 handbags, 8 apples, 1 book, \n",
      "384x640 4 persons, 2 handbags, 8 apples, 1 book, 1 clock, \n",
      "212/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 8 apples, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 8 apples, 1 book, \n",
      "213/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 2 handbags, \n",
      "384x640 5 persons, 2 handbags, 9 apples, \n",
      "384x640 5 persons, 2 handbags, 9 apples, 1 book, \n",
      "214/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 2 handbags, \n",
      "384x640 5 persons, 2 handbags, 8 apples, \n",
      "384x640 5 persons, 2 handbags, 8 apples, 1 book, \n",
      "215/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 2 handbags, \n",
      "384x640 5 persons, 2 handbags, 9 apples, \n",
      "384x640 5 persons, 2 handbags, 9 apples, 1 book, \n",
      "384x640 5 persons, 2 handbags, 9 apples, 1 book, 1 clock, \n",
      "216/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 10 apples, \n",
      "384x640 4 persons, 2 handbags, 10 apples, 1 book, \n",
      "384x640 4 persons, 2 handbags, 10 apples, 1 book, 1 clock, \n",
      "217/228 frames processed\n",
      "384x640 4 persons, \n",
      "384x640 4 persons, 2 handbags, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 13 apples, \n",
      "384x640 4 persons, 2 handbags, 1 bowl, 13 apples, 1 clock, \n",
      "218/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 umbrella, \n",
      "384x640 5 persons, 1 umbrella, 10 apples, \n",
      "384x640 5 persons, 1 umbrella, 10 apples, 1 clock, \n",
      "219/228 frames processed\n",
      "384x640 6 persons, \n",
      "384x640 6 persons, 1 umbrella, \n",
      "384x640 6 persons, 1 umbrella, 1 handbag, \n",
      "384x640 6 persons, 1 umbrella, 1 handbag, 1 bowl, \n",
      "384x640 6 persons, 1 umbrella, 1 handbag, 1 bowl, 12 apples, \n",
      "384x640 6 persons, 1 umbrella, 1 handbag, 1 bowl, 12 apples, 1 book, \n",
      "384x640 6 persons, 1 umbrella, 1 handbag, 1 bowl, 12 apples, 1 book, 1 clock, \n",
      "220/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 bowl, \n",
      "384x640 5 persons, 1 bowl, 13 apples, \n",
      "384x640 5 persons, 1 bowl, 13 apples, 1 book, \n",
      "384x640 5 persons, 1 bowl, 13 apples, 1 book, 1 clock, \n",
      "221/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 bowl, \n",
      "384x640 5 persons, 1 bowl, 11 apples, \n",
      "384x640 5 persons, 1 bowl, 11 apples, 1 book, \n",
      "384x640 5 persons, 1 bowl, 11 apples, 1 book, 1 clock, \n",
      "222/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 bowl, \n",
      "384x640 5 persons, 1 bowl, 10 apples, \n",
      "384x640 5 persons, 1 bowl, 10 apples, 1 book, \n",
      "384x640 5 persons, 1 bowl, 10 apples, 1 book, 1 clock, \n",
      "223/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 bowl, \n",
      "384x640 5 persons, 1 bowl, 9 apples, \n",
      "384x640 5 persons, 1 bowl, 9 apples, 1 book, \n",
      "384x640 5 persons, 1 bowl, 9 apples, 1 book, 1 clock, \n",
      "224/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 bowl, \n",
      "384x640 5 persons, 1 bowl, 8 apples, \n",
      "384x640 5 persons, 1 bowl, 8 apples, 1 book, \n",
      "384x640 5 persons, 1 bowl, 8 apples, 1 book, 1 clock, \n",
      "225/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 bowl, \n",
      "384x640 5 persons, 1 bowl, 10 apples, \n",
      "384x640 5 persons, 1 bowl, 10 apples, 1 book, \n",
      "384x640 5 persons, 1 bowl, 10 apples, 1 book, 1 clock, \n",
      "226/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 bowl, \n",
      "384x640 5 persons, 1 bowl, 10 apples, \n",
      "384x640 5 persons, 1 bowl, 10 apples, 1 book, \n",
      "384x640 5 persons, 1 bowl, 10 apples, 1 book, 1 clock, \n",
      "227/228 frames processed\n",
      "384x640 5 persons, \n",
      "384x640 5 persons, 1 bowl, \n",
      "384x640 5 persons, 1 bowl, 8 apples, \n",
      "384x640 5 persons, 1 bowl, 8 apples, 1 book, \n",
      "384x640 5 persons, 1 bowl, 8 apples, 1 book, 1 clock, \n",
      "228/228 frames processed\n"
     ]
    }
   ],
   "source": [
    "# Initializing video object\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "#Video information\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "nframes = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Initialzing object for writing video output\n",
    "output = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'XVID'), fps, (w, h))\n",
    "torch.cuda.empty_cache()\n",
    "# Initializing model and setting it for inference\n",
    "with torch.no_grad():\n",
    "  weights, imgsz = opt['weights'], opt['img-size']\n",
    "  set_logging()\n",
    "  device = select_device(opt['device'])\n",
    "  half = device.type != 'cpu'\n",
    "  model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "  stride = int(model.stride.max())  # model stride\n",
    "  imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
    "  if half:\n",
    "    model.half()\n",
    "\n",
    "  names = model.module.names if hasattr(model, 'module') else model.names\n",
    "  colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "  if device.type != 'cpu':\n",
    "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "\n",
    "  classes = None\n",
    "  if opt['classes']:\n",
    "    classes = []\n",
    "    for class_name in opt['classes']:\n",
    "\n",
    "      classes.append(names.index(class_name))\n",
    "\n",
    "  if classes:\n",
    "\n",
    "    classes = [i for i in range(len(names)) if i not in classes]\n",
    "\n",
    "  for j in range(nframes):\n",
    "\n",
    "      ret, img0 = video.read()\n",
    "\n",
    "      if ret:\n",
    "        img = letterbox(img0, imgsz, stride=stride)[0]\n",
    "        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "        img = np.ascontiguousarray(img)\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "          img = img.unsqueeze(0)\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img, augment= False)[0]\n",
    "\n",
    "\n",
    "        pred = non_max_suppression(pred, opt['conf-thres'], opt['iou-thres'], classes= classes, agnostic= False)\n",
    "        t2 = time_synchronized()\n",
    "        for i, det in enumerate(pred):\n",
    "          s = ''\n",
    "          s += '%gx%g ' % img.shape[2:]  # print string\n",
    "          gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]\n",
    "          if len(det):\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "\n",
    "            for c in det[:, -1].unique():\n",
    "              n = (det[:, -1] == c).sum()  # detections per class\n",
    "              s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "              print(s)\n",
    "\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "\n",
    "              label = f'{names[int(cls)]} {conf:.2f}'\n",
    "              plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "\n",
    "        print(f\"{j+1}/{nframes} frames processed\")\n",
    "        output.write(img0)\n",
    "      else:\n",
    "        break\n",
    "output.release()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='output_display.avi' target='_blank'>output_display.avi</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\Ahmme\\Downloads\\Yolo-20231224T203553Z-001\\Yolo\\yolov7\\output_display.avi"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# ... (Previous code remains unchanged)\n",
    "\n",
    "# Release the output video capture object\n",
    "output.release()\n",
    "video.release()\n",
    "\n",
    "# Reopen the output video file for display\n",
    "output_video = cv2.VideoCapture('output.mp4')\n",
    "\n",
    "# Define the codec and create a VideoWriter object for saving the displayed video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_display = cv2.VideoWriter('output_display.avi', fourcc, fps, (w, h))\n",
    "\n",
    "while True:\n",
    "    ret, frame = output_video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Output Video', frame)\n",
    "\n",
    "    # Write the frame to the new video file\n",
    "    output_display.write(frame)\n",
    "\n",
    "    # Break the loop if the user presses 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the output video capture and display objects\n",
    "output_video.release()\n",
    "output_display.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Create a download link for the displayed video file\n",
    "display_link = FileLink('output_display.avi')\n",
    "display_link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  v0.1-128-ga207844 torch 2.1.0+cu118 CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "480x640 1 person, \n",
      "480x640 1 person, \n",
      "480x640 1 person, \n",
      "480x640 1 person, \n",
      "480x640 1 person, \n",
      "480x640 1 person, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 2 apples, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 sports ball, \n",
      "480x640 1 person, 1 sports ball, 1 apple, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 sports ball, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 sports ball, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 apple, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 apple, \n",
      "480x640 1 person, 1 apple, 1 hot dog, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 apple, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 apple, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 apple, \n",
      "480x640 2 persons, \n",
      "480x640 2 persons, 1 apple, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 sports ball, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 banana, \n",
      "480x640 1 person, 1 banana, 1 apple, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 sports ball, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 apple, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 sports ball, \n",
      "480x640 2 persons, \n",
      "480x640 2 persons, 1 apple, \n",
      "480x640 1 person, \n",
      "480x640 1 person, \n",
      "480x640 1 person, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 orange, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 sports ball, \n",
      "480x640 1 person, 1 sports ball, 1 orange, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 orange, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 teddy bear, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 orange, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 orange, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 sports ball, \n",
      "480x640 1 person, \n",
      "480x640 1 person, 1 orange, \n",
      "480x640 1 person, \n",
      "480x640 1 person, \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from utils.general import non_max_suppression, scale_coords\n",
    "from utils.torch_utils import select_device\n",
    "# Initializing video object for camera input\n",
    "video = cv2.VideoCapture(0)  # 0 corresponds to the default camera\n",
    "\n",
    "# Video information (adjust as needed)\n",
    "fps = 30  # Adjust the frame per second according to your camera\n",
    "w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "nframes = 0  # For camera input, set the number of frames to 0\n",
    "torch.cuda.empty_cache()\n",
    "# Initializing model and setting it for inference\n",
    "with torch.no_grad():\n",
    "  weights, imgsz = opt['weights'], opt['img-size']\n",
    "  set_logging()\n",
    "  device = select_device(opt['device'])\n",
    "  half = device.type != 'cpu'\n",
    "  model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "  stride = int(model.stride.max())  # model stride\n",
    "  imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
    "  if half:\n",
    "    model.half()\n",
    "\n",
    "  names = model.module.names if hasattr(model, 'module') else model.names\n",
    "  colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "  if device.type != 'cpu':\n",
    "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "\n",
    "  classes = None\n",
    "  if opt['classes']:\n",
    "    classes = []\n",
    "    for class_name in opt['classes']:\n",
    "\n",
    "      classes.append(names.index(class_name))\n",
    "\n",
    "  if classes:\n",
    "\n",
    "    classes = [i for i in range(len(names)) if i not in classes]\n",
    "\n",
    "  for j in range(nframes):\n",
    "\n",
    "      ret, img0 = video.read()\n",
    "\n",
    "      if ret:\n",
    "        img = letterbox(img0, imgsz, stride=stride)[0]\n",
    "        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "        img = np.ascontiguousarray(img)\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "          img = img.unsqueeze(0)\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img, augment= False)[0]\n",
    "\n",
    "\n",
    "        pred = non_max_suppression(pred, opt['conf-thres'], opt['iou-thres'], classes= classes, agnostic= False)\n",
    "        t2 = time_synchronized()\n",
    "        for i, det in enumerate(pred):\n",
    "          s = ''\n",
    "          s += '%gx%g ' % img.shape[2:]  # print string\n",
    "          gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]\n",
    "          if len(det):\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "\n",
    "            for c in det[:, -1].unique():\n",
    "              n = (det[:, -1] == c).sum()  # detections per class\n",
    "              s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "\n",
    "              label = f'{names[int(cls)]} {conf:.2f}'\n",
    "              plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "\n",
    "        print(f\"{j+1}/{nframes} frames processed\")\n",
    "        output.write(img0)\n",
    "      else:\n",
    "        break\n",
    "while True:\n",
    "    ret, img0 = video.read()\n",
    "\n",
    "    if ret:\n",
    "        img = letterbox(img0, imgsz, stride=stride)[0]\n",
    "        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "        img = np.ascontiguousarray(img)\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img, augment=False)[0]\n",
    "        pred = non_max_suppression(pred, opt['conf-thres'], opt['iou-thres'], classes=classes, agnostic=False)\n",
    "        t2 = time_synchronized()\n",
    "\n",
    "        for i, det in enumerate(pred):\n",
    "            s = ''\n",
    "            s += '%gx%g ' % img.shape[2:]  # print string\n",
    "            gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]\n",
    "            if len(det):\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "                    print(s)\n",
    "\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    label = f'{names[int(cls)]} {conf:.2f}'\n",
    "                    plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "\n",
    "        cv2.imshow('Result', img0)\n",
    "\n",
    "        # Write the frame to the output video file\n",
    "        output.write(img0)\n",
    "\n",
    "        # Break the loop if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the video capture and video writer objects\n",
    "video.release()\n",
    "output.release()\n",
    "\n",
    "# Destroy all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
